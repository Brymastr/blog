[
  {
    "title": "AWS VPCs and Docker Networks",
    "slug": "aws-vpcs-and-docker-compose",
    "content": "<hr><h3 id=\"tldr-\">TLDR:</h3><p>I recently ran into an issue where I lost SSH access to one of my primary environments. I spent 12 hours on my own and 3 with AWS support trying to troubleshoot this problem. In the end I found that the problem was an IP address conflict between Docker and a peered VPC.</p><hr><h3 id=\"situation\">Situation</h3><p>Our AWS usage has drastically increased over the past two years. We have been working on several integration projects for the purposes of automated marketing, business intelligence, and several customer-facing features. Our most recent project is a new customer offering that should be an exciting one to follow. From a technical perspective it’s not all that exceptional and consists of a new page on our ecommerce site, a new API with 3 endpoints, a relatively low-traffic Redis cache, and a new Docker network.</p><p>Before I was ready to deploy any portions of this new offering I wanted to increase the security and maturity of our EC2 instances in terms of SSH and HTTP.</p><h3 id=\"better-security\">Better Security</h3><p>Originally the EC2 instances for various projects were running on a suboptimal security and access design where specific IPs were whitelisted for SSH access and most instances were allowing HTTP on 80 and 443 from any IP. I was unhappy with this strategy as non-static IP addresses tend to change and it’s difficult to stay up to date with the list of whitelisted IPs and which organization related locations they represent. Not to mention the vulnerability of unauthorized SSH connection attempts and HTTP traffic.</p><p>Before I describe my new approach I need to explain our slightly less than common AWS VPC configuration. We function primarily out of two VPCs peered together with differing IP supernets in order to separate core operations from marketing and analytics. VPC A uses the default IP CIDR of <code>172.31.0.0/16</code> while VPC B uses the <code>10.0.0.0/16</code> CIDR supernet. This was done to avoid any potential networking conflicts. VPC A consists entirely of private subnets and is only accessible behind a VPN running within. VPC B has some customer-facing services but is otherwise entirely private. At this point, for various reasons, we only had a VPN configured to access VPC A and not VPC B.</p><p>My new design was to set up a small bastion server in VPC A and to use the VPN from VPC A to SSH into it as an SSH entry point for all environments in VPC B. The bastion would contain the SSH key and IPs of all other environments for the project in question. I would set up a new fleet of security groups to allow for HTTP and SSH traffic over the appropriate ports between the appropriate environments.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2019/09/Peered-VPCs.svg\" class=\"kg-image\" alt><figcaption>An oversimplified diagram of my new approach to our VPC and EC2 security setup for this project.</figcaption></figure><p>I was able to execute on this plan and had tested that all connections and services were functioning as expected. Once security was up to standard I was ready to deploy the aforementioned new feature to our development, and subsequently production, environment.</p><h3 id=\"problem\">Problem</h3><p>The deployment to the development environment went smoothly and I was able to test that things still worked. When I moved on to production and ran <code>docker-compose up</code> I saw that the new services and networks had come up but also that my connection to the server had frozen. I closed the terminal window and attempted to reconnect to the server but the connection refused to work. I’d seen this sort of connection issue before many times and it almost always signified a security group misconfiguration which made a lot of sense to me at the time as I had just finished revamping my security groups.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2019/09/Screen-Shot-2019-09-27-at-4.53.46-PM.png\" class=\"kg-image\" alt><figcaption>ssh hangs when attempting to access the production instance</figcaption></figure><p>After taking a deep look at my security groups and concluding that things were done correctly I made a secondary conclusion that I must be really wrong in my understanding of how security groups work. I was completely baffled as to why I could access the Development environment but could not access the Production environment despite the fact that both machines were running the same OS with the same code and same security groups.</p><p>After a day and a half of troubleshooting this problem on my own I decided to open a ticket with AWS support. Together we tried everything I’d already done as well as some other ideas that the support agent came up with. They raised the idea of temporarily assigning a public IP and a new security group that allows for SSH access from our office IP address. This is basically the same configuration I had before my security group overhaul so I thought it could work and, sure enough, I was able to SSH into the production server via this method.</p><p>The course of action now was to find out what was wrong with the software running in the Production environment and how it was different from the fully functioning Development environment. Both Ubuntu machines had the same <a href=\"https://help.ubuntu.com/community/UFW\">UFW</a> configuration, the same <a href=\"https://wiki.archlinux.org/index.php/iptables\">iptables</a> structure, and were located within the same availability zone and subnet.</p><h3 id=\"a-promising-solution\">A Promising Solution</h3><p>Since I had success with the temporary workaround public IP and open security group and had likely narrowed the problem down to software running on the instance I decided to take all of my accumulated troubleshooting results and go back to Google the next morning to see what I could find. At this point I was so tired and frustrated that I don’t remember exactly what search terms I used but I came across <a href=\"https://stackoverflow.com/questions/50514275/docker-bridge-conflicts-with-host-network\">a promising StackOverflow</a> post discussing how Docker networks can sometimes conflict with existing subnets. The post described how, by default, docker networks are created in the <code>172.N.0.0/16</code> range of IPs, where N is a somewhat random number that seems to fall between 15 and 35. This prompted me to investigate which subnets the docker networks were being assigned on my problematic VM. I ran <code>docker network list</code> to view a list of networks with their IDs. </p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2019/09/Screen-Shot-2019-09-27-at-4.28.26-PM.png\" class=\"kg-image\" alt><figcaption>docker network list. network names redacted</figcaption></figure><p>That output a list of the docker networks running on the instance. I then ran <code>docker network inspect &lt;NETWORK ID&gt;</code> on each network ID to view the assigned subnet and mask. The allocated subnets were <code>172.30.0.0/16</code>, <code>172.31.0.0/16</code>, all the way to <code>172.38.0.0/16</code>. If you recall from earlier I mentioned that VPC A, the VPC that the bastion was running in, is assigned the <code>172.31.0.0/16</code> CIDR block. AHAAA! </p><p>This is clearly a conflict! It provides an explanation as to why SSH stopped functioning from the bastion as well as why SSH did function over the public IP. This was such fantastic news and lifted my spirits significantly enough to continue fixing things up, even though I had seriously considered giving up on many occasions over the past two days.</p><p>Why then did my Development environment not run into the same issue when creating that same new docker network? I ran the same docker network inspect command on each of the networks in Development and found that the subnets ranged from <code>172.21.0.0/16</code> to <code>172.29.0.0/16</code>. I couldn’t find clear documentation on how Docker chooses to assign subnets to new networks but as far as I can tell it’s random. Maybe there is something else on the VM using <code>172.0.x.x</code> to <code>172.20.x.x</code> but for my concerns the only reason my Production instance was affected and not my Development instance was pure chance.</p><h3 id=\"back-to-productivity\">Back to Productivity</h3><p>This was the most frustrating and baffling problem I’ve had to work on recently and there were several moments where I seriously considered starting from scratch. There were also moments where I wondered how I’d ever sleep again or even call myself a developer if I couldn’t figure this out. I felt I had let down myself, my peers, and my company. Upon solving the issue though I realized I learned several valuable lessons in DevOps and gained a much deeper understanding of the AWS network stack as a whole. I'm a better developer because of this experience but I still occasionally hate AWS.</p>",
    "created_at": "2019-09-24T03:55:42.000Z",
    "updated_at": "2019-10-26T23:59:00.000Z",
    "published_at": "2019-10-26T23:59:00.000Z",
    "preview": "I recently ran into an issue where I lost SSH access to one of my primary environments. This issue made me question my career choice but resulted in lessons learned."
  },
  {
    "title": "Me",
    "slug": "me",
    "content": "<p>I’m a mixed bag Software Engineer living in the best place on earth, Vancouver BC. I am currently working at <a href=\"https://baileynelson.com\">Bailey Nelson</a>, a forward-thinking eyewear and eye-care company based in Sydney, Australia building both internal systems and customer facing products.</p><p>I love the power that fingers on a keyboard can have and I crave the kind of success that can come from technology and programming. There have been many times in my career where I have come across a problem that was not immediately solvable by a simple Google or StackOverflow search. It took me a while to realize that my solutions to said problems may be a learning opportunity for others struggling with similar issues. I’ve decided to start documenting any tasks I work on that I think are interesting or more difficult than expected. I welcome comments on these posts that foster discussion, suggest amendments, or simply offer opinions.</p><p>I don’t have an email list, a podcast, or any products to sell. I just want to provide a window into a software engineer’s day to day and I hope to be a relatable 3rd party opinion to other developers.</p>",
    "created_at": "2019-09-27T22:35:32.000Z",
    "updated_at": "2019-09-27T22:38:41.000Z",
    "published_at": "2019-09-27T22:38:03.000Z",
    "preview": "I’m a mixed bag Software Engineer living in the best place on earth, Vancouver BC. I am currently working at Bailey Nelson, an eyewear and eye-care company based in Sydney Australia, building both internal systems and customer facing products."
  },
  {
    "title": "Prime Spirals",
    "slug": "my-ulam-spiral",
    "content": "<hr><h3 id=\"tldr-\">TLDR:</h3><p>Prime Spirals are an interesting topic to me and I wanted to play around with them in website format. I was dissatisfied with the existing offerings so I decided to make my own... 3 times in 5 years. <a href=\"https://spiral.dorsay.dev\">Try it out here</a>.</p><hr><p>A few years ago I stumbled across <a href=\"https://www.youtube.com/watch?v=iFuR97YcSLM\">a video</a> on the YouTube channel \"<a href=\"https://www.youtube.com/channel/UCoxcjq-8xIDTYp3uz647V5A\">Numberphile</a>\" talking about Prime Spirals. I found it fascinating that this phenomenon can exist and it blew my mind that I had only just discovered it. I wanted to play around with this in website or app format but the only pages I could find weren't exactly what I was looking for. This seemed like an interesting idea so I decided to make my own.</p><p>In primary school my friends and I played a computer game called <a href=\"https://en.wikipedia.org/wiki/Munchers#Number_Munchers\">Number Munchers</a>. You play as a little green character on a 5x6 grid of numbers with the goal of eating all of the numbers that match the selected category. My favourite category to play was prime numbers and I think the game was the only time I learned about primes in school. I managed to get quite good at identifying primes over the years of playing the game and I'm certain it's partly responsible for my interest in this topic. If you're unfamiliar with the game you can play it <a href=\"https://classicreload.com/number-munchers.html\">here</a>. </p><p>Before I go into detail about my multiple attempts at building a web-based prime spiral I should briefly explain prime numbers and what a prime spiral is.</p><h3 id=\"prime-numbers\">Prime Numbers</h3><p>A prime number is one that has no factors except for 1 and itself. For example 7 is a prime number because it has not other factors whereas the number 21 is not prime because it has factor pairs 21,1 and 7,3. Numbers which are not prime are called Composite numbers and eating those in Number Munchers will lose you a life.</p><p>Prime numbers are not possible to predict but there are <a href=\"https://www.qsleap.com/gmat/resources/math-basics-prime-numbers\">some rules</a> around deciding if a number is prime or composite:</p><ol><li>An even number can always be divided by 2 so all primes other than 2 must be odd numbers</li><li>Any number ending in a 5 is divisible by 5 which makes it composite</li><li>A number in which the sum of its digits is divisible by 3 will also be divisible by 3 and therefore composite. Example:<br>- <strong>21:</strong>  2 + 1 = 3 % 3 = 0. composite<br>- <strong>2874: </strong>2 + 8 + 7 + 4 = 21 % 3 = 0. composite<br>- <strong>199:</strong> 1 + 9 + 9 = 19 % 3 = 1. prime</li><li>Double the last digit and subtract it from the rest of the number and if the result is divisible by 7 then the original number is also divisible by 7 and therefore composite. Example:<br>- <strong>9233:</strong> 923 - (3 * 2) = 917 % 7 = 0. composite</li></ol><p>These rules pulled from here: <a href=\"https://www.qsleap.com/gmat/resources/math-basics-prime-numbers\">https://www.qsleap.com/gmat/resources/math-basics-prime-numbers</a></p><p>These rules and others have helped increase the rate of prime discovery over time. When I first became interested in the topic the largest discovered prime was 2<sup>57,885,161</sup> - 1 and at the time of writing this post the largest was 2<sup>82,589,933</sup> - 1.</p><h3 id=\"prime-spirals\">Prime Spirals</h3><p>I'll keep this spiral explanation brief as the linked video and other documentation describes it nicely already. The first prime spiral was discovered/invented by a Polish scientist named Stanislaw Ulam in 1963. He was doodling numbers on a piece of paper in creative patterns and landed on one with interesting properties.</p><p>A prime spiral works like this: The number 1 is written as a starting point, then the number 2 is written just to the right of 1. 3 above 2, 4 left of 3, again 5 left of 4, then 6 below 5 and left of 1... maybe this is best described in an image.</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2019/10/Prime-Spiral.png\" class=\"kg-image\" alt></figure><p>This is simply the first 9 numbers but the rest continue in the same manner. The next step is to highlight all of the prime numbers like so:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2019/10/Prime-Spiral-Primes.png\" class=\"kg-image\" alt></figure><p> The interesting part is that as you scale this up a pattern of diagonal lines starts to appear. The pattern is subtle and appears random which makes sense because prime numbers are for the most part unpredictable. </p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2019/10/Spiral-3000.png\" class=\"kg-image\" alt></figure><p>What's even stranger is that if you start the spiral at 41 instead of 1 and count outward in the same pattern you get a much longer diagonal line spanning from the middle. The reason this fascinates me is simply that a number system that is theoretically unpredictable arranged in a specific way can produce a somewhat predictable image.</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2019/10/Spiral-3000-41.png\" class=\"kg-image\" alt></figure><h3 id=\"building-a-web-spiral\">Building a web spiral</h3><p>I first decided to work on a web version of a prime spiral back in 2014 when I was a student. Back then I didn't know how git worked and I no longer have the code lying around but I'm sure if I did it would be a cringey look into my coding style as a university student.</p><h3 id=\"v1-jquery\">v1 - jQuery</h3><p>As with most of my fun side projects, Version 1 of my prime spiral was an excuse to learn a new technology. At the time I was just getting into web development and the technology I wanted to learn was jQuery. jQuery gets looked down on a lot for being a completely overkill choice when the only function that gets used is the selector and this project was no exception. To make things worse I was calculating factors for each number. My initial commit of V2 used the same prime calculation algorithm as V1.</p><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-javascript\">function isPrime(num) {\n  if (num &lt; 2) return false;\n  for (var i = 2; i &lt;= num; i++) {\n    if (num % i == 0) {\n      return false;\n    }\n  }\n  return true;\n};</code></pre><figcaption>please excuse my naive 2014 javascript</figcaption></figure><p>When trying to calculate if the number 21 is prime I needed to check if each number between 2 and 21 is a factor. The time complexity of this calculation is O(n) where n is 21 but I needed to calculate prime-ness for each number up to 21. This made my algorithm's time complexity O(n<sup>2</sup>). In order to calculate primes up to 21 it took 441 calculations minus a few since I started at 2. Calculating primes up to 10,000 would have required 100 million calculations.</p><h3 id=\"v2-angular\">v2 - Angular</h3><!--kg-card-begin: markdown--><p>The next semester of school was during the explosion of new Javascript frameworks, or at least when I became privy to it, so naturally the next technology I wanted to learn was Angular. With Angular I was able to take advantage of the <code>ng-repeat</code> directive to easily produce N simple square divs. For every number in the loop I calculated if it was a prime and set the background color if it was. Also before every iteration I calculated which direction the next square would be placed in.</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-code-card\"><pre><code class=\"language-html\">&lt;div id=\"spiral\" class=\"container\"&gt;\n  &lt;div class=\"item\"\n       ng-repeat=\"i in getNumber(upperBound - lowerBound + 1) track by $index\"\n       ng-class=\"{prime: isPrime($index + lowerBound)}\"\n       ng-init=\"positionDiv($index + 1)\"&gt;\n    {{$index + lowerBound}}\n  &lt;/div&gt;\n&lt;/div&gt;</code></pre><figcaption>actual code from 2015</figcaption></figure><p>As with the jQuery version this site was not very performant; Even with a few improvements to the algorithm. I was now only calculating factors up to a square root of  the current number which reduced the time complexity to O(sqrt(n)). The bottleneck of this new version was that I was generating more HTML DOM elements than the browser and my Core 2 duo 2011 MacBook Pro could handle. The actual code is available at <a href=\"https://github.com/Brymastr/spiral/tree/9ae9344be8cb58603ee18cac6cba688ab08fd5cb\">this 2015 commit</a> but looks something like this:</p><pre><code class=\"language-javascript\">function isPrime(num) {\n  const sqrt = Math.floor(Math.sqrt(num));\n  for (let i = 2; i &lt; sqrt; i++)\n    if (num % i === 0) return false;\n  return num &gt; 1;\n}</code></pre><h3 id=\"v3-vue\">v3 - Vue</h3><p>Fast forward to mid 2019 and I'd come a long way in my career and knowledge and so had browser technology. With this version I looked at the shortcomings of the previous two and came up with a plan to improve upon them.</p><p>The first obvious area for improvement was the calculation of prime numbers. I decided to get around even needing to calculate primes at all by downloading a list of the <a href=\"https://primes.utm.edu/lists/small/millions/\">first 2 million</a> primes. I then converted that list of primes into a simple text file where <code>0</code> represents composite and <code>1</code> represents prime and each bit represents an integer from 1 to 32,452,843. For example, the first 50 bits look like this:</p><!--kg-card-begin: markdown--><pre><code>0110101000101000101000100000101000001000101000100\n</code></pre>\n<!--kg-card-end: markdown--><p>This ~30.1MB file (1.6MB gzipped) is hosted on a simple express API at <a href=\"https://primes.dorsay.dev\">https://primes.dorsay.dev</a> so that it can be streamed to the vue app (or random internet stranger) upon request. The API adds the <code>Cache-Control</code> header with a large max-age so your browser will fetch the primes from local cache until you clear it or you use Firefox Focus. On a decent internet connection, without cacheing, in the pacific northwest this only takes ~570ms to download which is a massive improvement over calculating each prime on the client.</p><p>The next major area for improvement was decreasing the sheer number of DOM elements that get rendered. I opted for using the <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API\">HTML5 Canvas API</a>. This was my first time using it but it was quite straightforward. The algorithm to calculate where to place the next square remained unchanged but now instead of rendering a div I'm making a call to <code>fillRect</code> for each square. The result is a single rendered element.</p><pre><code class=\"language-html\">&lt;canvas id=\"canvas\"&gt;&lt;/canvas&gt;</code></pre><p>As the first two versions were quite basic and the max number could not be changed I wanted this version to have a control panel that could control the zoom, starting number, ending number, and the colour of the squares. I also wanted these control parameters to be saved for future sessions. I opted to use my current favourite frontend javascript framework, VueJS. I've been using it for a while now and the quality of life improvements I get from using the vue-cli to generate new projects and my familiarity with the framework justify the likely increase in initial page load time.</p><p>If you'd like to mess around with v3 you can try it out at <a href=\"https://spiral.dorsay.dev\">https://spiral.dorsay.dev</a>. The code for this project is available at <a href=\"https://github.com/Brymastr/spiral/tree/vue\">my Github account</a>.</p><h3 id=\"conclusion\">Conclusion</h3><p>There are many more ways to improve upon my naive methods of calculating prime numbers. There's a reason that there are challenges with monetary rewards to calculate the next prime number beyond what is currently possible. When it comes to theories and conjectures and whatnots I don't really know what I'm talking about and that's not the point of this post. I just wanted to show off my fun little project. People much smarter than me can explain this much better and will probably make further steps to solving the prime pattern in the near future. I find this to be a fascinating phenomenon that will hopefully one day become a formula.</p><p>This is the article that inspired me to publish my spiral site and this post: <a href=\"https://www.wired.com/story/a-big-question-about-prime-numbers-gets-a-partial-answer/\">https://www.wired.com/story/a-big-question-about-prime-numbers-gets-a-partial-answer/</a></p>",
    "created_at": "2019-10-21T06:19:26.000Z",
    "updated_at": "2020-08-09T07:14:29.000Z",
    "published_at": "2019-10-26T21:45:00.000Z",
    "preview": "Prime Spirals are an interesting topic to me and I wanted to play around with them in website format. I was dissatisfied with the existing offerings so I decided to make my own... 3 times in 5 years. Try it out here."
  },
  {
    "title": "My Development Environment",
    "slug": "my-development-environment",
    "content": "<p>This is about my preferred tech stacks, operating systems, and tools that I like to use in my everyday programming life because it's fun to talk about.</p><h3 id=\"my-job\">My Job</h3><h3 id=\"operating-systems\">Operating Systems</h3><h3 id=\"languages\">Languages</h3><h3 id=\"architecture\">Architecture</h3><h3 id=\"devops\">DevOps</h3><h3 id=\"workflows\">Workflows</h3>",
    "created_at": "2019-10-26T21:22:40.000Z",
    "updated_at": "2019-10-26T21:26:59.000Z",
    "published_at": "2019-10-26T21:22:40.000Z",
    "preview": "I detail my preferred software development system environment"
  },
  {
    "title": "Encrypting Kubernetes Secrets",
    "slug": "encrypting-kubernetes-secrets",
    "content": "<p>Kubernetes Secrets are a useful way to securely load private data like passwords and api keys into a K8s cluster. I have found loads of documentation about how to use them and their benefits but very little on how to store the files safely. I upload all my code to Github but one should never include secrets in that uploaded code so how to you maintain the secrets files? I created a simple way to encrypt the files before committing them to git.</p>",
    "created_at": "2019-10-26T21:28:11.000Z",
    "updated_at": "2019-10-26T21:31:18.000Z",
    "published_at": "2019-10-26T21:31:18.000Z",
    "preview": "Encrypting Kubernetes Secrets"
  },
  {
    "title": "Git clone and cd in one command",
    "slug": "git-clone-and-change-directories-in-one-command",
    "content": "<p>I do most of my work from my company-provided 13\" MacBook Pro. I like its small and portable form factor that allows me to work from the office or from wherever I happen to be when inspiration hits. I also get the opportunity to work from home occasionally which I like to take advantage of. In 2015 I built a desktop computer to play games on but over the years I've become very productive when performing work tasks on it.</p><p>I prefer to keep my disks as minimalist as possible and the the Bailey Nelson GitHub organization has over 30 repositories on it so I tend to only clone repos as I need them and delete them from my computer when I'm done with a task. The process of cloning repos every time I want to do some work isn't really a time consuming one but I did notice that I was using some repetitive keystrokes. Every time I sat down to do work I'd look up the repo name in GitHub and then open a terminal and type something like this:</p><pre><code class=\"language-bash\">brycen:~$ cd Documents/Projects\nbrycen:~/Documents/Projects$ git clone git@github.com:Bailey-Nelson/pipeline.git\nbrycen:~/Documents/Projects$ cd pipeline\nbrycen:~/Documents/Projects/pipeline$ code .</code></pre><p>This leaves me with a terminal open to my project directory and Visual Studio Code window open looking at my code. It's how I start most of my from-home days and I thought it was just a few more keystrokes than I felt I needed to type each morning. This is certainly a first world problem but, as developers, what good are we if we're not constantly improving? I decided to write a quick script that would simplify this process. With this script my new workflow is 2 commands instead of 4.</p><pre><code class=\"language-bash\">brycen:~$ switch pipeline\nCloning into '~/dev/github.com/bailey-nelson/pipeline'...\nswitching to \"pipeline\"\nbrycen:~/dev/github.com/bailey-nelson/pipeline$ code .</code></pre><p>Firstly this saves a bit of time and a few keystrokes when cloning repos from GitHub. Secondly I find this helps me quickly change directories to a local repo when my terminal is at some completely different location without having to think about where the target repo is relatively. For example if my terminal is at <code>/etc/update-motd.d/</code> and I want to switch to a local git repo I don't need to type <code>cd ~/dev/github.com/bailey-nelson/pipeline</code>. Or if my terminal is at <code>~/dev/github.com/brymastr/blog/themes</code> I don't need to figure out how to navigate to where I want to go with a bunch of dots like <code>../../../bailey-nelson/pipeline</code>.</p><p>I needed to decide on a folder structure for repos cloned with this script. I decided on <code>~/dev/github.com/&lt;org name&gt;/&lt;repo name&gt;</code> as I've seen it in two other companies recently and it's been working for me. In theory it doesn't really matter where repos are cloned to if you use <code>switch</code> for every project since the structure is handled and locality relativity is irrelevant.</p><p>It's a slight improvement that was fun to write. The script is public on the Bailey Nelson GitHub repository available at the link below. Feel free to install it for your own use or fork it to make your own tweaks.</p><figure class=\"kg-card kg-bookmark-card\"><a class=\"kg-bookmark-container\" href=\"https://github.com/Bailey-Nelson/switch\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Bailey-Nelson/switch</div><div class=\"kg-bookmark-description\">switch to a specified github repository; clone if not found locally - Bailey-Nelson/switch</div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"https://github.githubassets.com/favicon.ico\"><span class=\"kg-bookmark-author\">Bailey-Nelson</span><span class=\"kg-bookmark-publisher\">GitHub</span></div></div><div class=\"kg-bookmark-thumbnail\"><img src=\"https://avatars0.githubusercontent.com/u/34111609?s&#x3D;400&amp;v&#x3D;4\"></div></a></figure>",
    "created_at": "2019-10-26T21:32:40.000Z",
    "updated_at": "2019-10-28T00:26:11.000Z",
    "published_at": "2019-10-28T00:04:51.000Z",
    "preview": "I made a quick little script to save myself a few keystrokes when working with multiple git repositories."
  },
  {
    "title": "Accidentally sharing a volume between Redis containers",
    "slug": "accidentally-sharing-volumes-between-redis-containers",
    "content": "<p>I made a dumb mistake a few months back with one of my projects at work. I was doing some refactoring on a group of services orchestrated with Docker Compose and I noticed some shortcomings in the way I had set up a couple Redis databases. With the <a href=\"https://hub.docker.com/_/redis\">Redis docker image</a> you can persist your data to disk in order to withstand server restarts. The way this is done is by creating a Docker volume and mounting the <code>/data</code> directory. This is how I had things set up originally:</p><pre><code class=\"language-yaml\">version: \"3.7\"\nservices:\n  ...\n  \n  redis1:\n    image: \"redis:5.0.3-alpine\"\n    volumes:\n      - ./cache1:/data\n      \n  redis2:\n    image: \"redis:5.0.3-alpine\"\n    volumes:\n      - ./cache2:/data\n\nvolumes:\n  ...</code></pre><p>This resulted in two directories being created at the root of the project directory with one per service. I'd read about using <a href=\"https://docs.docker.com/compose/compose-file/\">Docker named volumes</a> especially in Docker Compose and wanted to switch to that instead of creating directories I'd never need to access. I switched my volume configuration to this:</p><pre><code class=\"language-yaml\">version: \"3.7\"\nservices:\n  ...\n  \n  redis1:\n    image: \"redis:5.0.3-alpine\"\n    volumes:\n      - cache:/data\n      \n  redis2:\n    image: \"redis:5.0.3-alpine\"\n    volumes:\n      - cache:/data\n\nvolumes:\n  ...\n  cache:</code></pre><p>I assumed that each service would create its own directories in the named <code>cache</code> volume like <code>cache:/redis1</code> and <code>cache:/redis2</code>. What really happened though was that all data created in one redis instances was available in both instances. In real life my services are not called redis1 and redis2 and are used to store different kinds of data. This took me way too long to notice and it was a major inconvenience to fix it. As far as I can tell you can't and shouldn't share named volumes between services unless it's a single scaled service. My solution was to create a separate named volume for each service.</p><pre><code class=\"language-yaml\">version: \"3.7\"\nservices:\n  ...\n  \n  redis1:\n    image: \"redis:5.0.3-alpine\"\n    volumes:\n      - cache1:/data\n      \n  redis2:\n    image: \"redis:5.0.3-alpine\"\n    volumes:\n      - cache2:/data\n\nvolumes:\n  ...\n  cache1:\n  cache2:</code></pre><p>This is just a quick story about a misunderstanding I had that wasted a lot of time. I hope this can save someone from the same frustration.</p>",
    "created_at": "2019-10-26T21:33:58.000Z",
    "updated_at": "2019-10-27T00:08:43.000Z",
    "published_at": "2019-10-27T00:08:43.000Z",
    "preview": "I had a misunderstanding of how Docker named volumes work that cost me a lot of time."
  },
  {
    "title": "Quotes and Other Things",
    "slug": "quotes-and-other-things-ive-learned",
    "content": "<p>This post is about some software engineering related things I've heard and learned in the past 7 years. Many of them also apply to other fields or just to life in general. I don't fully agree with everything but these are my thoughts.</p><h3 id=\"knuth-s-law-of-optimization\">Knuth's Law of Optimization</h3><ol><li>Understand the problem</li><li>Write a working solution </li><li>Optimize the solution</li></ol><p>This is very important when developing for an organization. As a developer you're paid to work fast and get things done. There are two times where a perfectly optimized solution matters to an organization, purely from a cost perspective:</p><ol><li>A service will experience very high usage and must be cost effective.</li><li>A service will undergo a large amount of development and growth in the future and should be written in a way that allows developers to be most productive.</li></ol><p>Systems and services that will have neither high load nor frequent development should be written quickly and concisely. I find this difficult to adhere to sometimes since I deeply enjoy designing well thought out and optimally implemented projects. I think it could be said that a developers skill can be judged based on the quality of work they can produce in a given time frame. </p><h3 id=\"if-it-makes-money-then-go-back-and-tidy-it-up-otherwise-move-on-jason-harrison\">\"If it makes money then go back and tidy it up, otherwise move on.\" - Jason Harrison</h3><p>This quote is closely related to Knuth's law but more tailored to personal projects. Jason Harrison was a professor of mine in university that taught my cohort PHP but more importantly instilled a desire to learn and a craving for success. He spoke often about his experience as a new developer and the projects he started with the goal of making as much money as possible. Wealth is not the only pursuit that matters in anyone's career but the sentiment really resonated with me as a broke university student. </p><p>The message is much the same as the last one. It's important to simply get something working before you can know if it's going to be a success. This quote encourages me to try out new ideas but also to not hang on to ideas that aren't going to work out. At this point in my career I haven't prioritized personal projects enough but I hope that one day this will matter.</p><h3 id=\"any-improvements-made-anywhere-besides-the-bottleneck-are-an-illusion-the-phoenix-project\">\"Any improvements made anywhere besides the bottleneck are an illusion.\" - The Phoenix Project</h3><p>This is the first quote I'll mention from a book called The Phoenix Project. If you haven't read it then I highly recommend giving it a read. This was said by character Gene Kim who was discussing productivity of a factory, and therefor a software firm. As a company tries to constantly improve their production rate, improvements should be done starting with the most pressing issue. Any improvements that do not alleviate the worst problem causing a slow down will not immediately increase production. Those changes may affect production rate in the future but that's just a maybe, and there may be other happenings in an organization that prevent those changes from ever providing the benefit they were intended for.</p><h3 id=\"being-able-to-take-needless-work-out-of-the-system-is-more-important-than-being-able-to-put-more-work-into-the-system-the-phoenix-project\">\"Being able to take needless work out of the system is more important than being able to put more work into the system.\" - The Phoenix Project</h3><p></p><h3 id=\"parkinson-s-law\">Parkinson's Law</h3><blockquote>Work expands so as to fill the time available for its completion.</blockquote><p>I find this law to be very true, either consciously or subconsciously, in both personal and organizational projects. It is rare for a project to complete ahead of schedule. When I've completed tasks early in my jobs I've been told to go back and check it over because I may have missed something. There's a fear that if a task was done quicker than the time that was estimated to complete it then there must be something that was missed. In addition to this fear I think that many developers want to complete their tasks as thoroughly as possible. If they finish something early then there is always more that can be done.</p><h3 id=\"progress-not-perfection-jonathan-queer-eye\">Progress not perfection - Jonathan, Queer Eye</h3><p></p><h3 id=\"there-are-always-more-things-to-do-than-people-to-do-them-ben-orenstein\">\"There are always more things to do than people to do them\" - Ben Orenstein</h3><p></p><h3 id=\"work-life-harmony-jeff-bezos\">Work life harmony - Jeff Bezos</h3><p></p><h3 id=\"the-further-away-from-the-person-signing-your-cheques-the-better\">The further away from the person signing your cheques the better</h3><p></p><h3 id=\"do-it-in-the-moment-or-not-at-all\">Do it in the moment, or not at all</h3><p></p><h3 id=\"it-s-not-a-good-sign-when-they-re-still-attaching-parts-to-the-space-shuttle-at-liftoff-time\">It's not a good sign when they're still attaching parts to the space shuttle at liftoff time</h3><p></p><h3 id=\"4-types-of-work\">4 types of work</h3><p></p><h3 id=\"if-you-can-t-make-me-learn-it-you-don-t-really-know-it-miles-johnston\">If you can't make me learn it, you don't really know it - Miles Johnston</h3><p></p><h3 id=\"grades-don-t-really-matter-in-the-workplace-jason-harrison\">\"Grades don't really matter in the workplace.\" - Jason Harrison</h3><p></p><h3 id=\"sleep-is-only-somewhat-important-me\">Sleep is only somewhat important - Me</h3><p>The university program I did was known for being difficult and a lot of work. Most science-based university programs are but this program had me and my classmates often staying up until the early hours of the morning completing math assignments and programming projects. There were at least 4 times where me and a group of peers stayed all night in our class' computer lab working on group assignments, ordering pizza and ramen to the school, and taking turns napping on the couch. The joke we often made was that sleep is for the weak. I think I took it a bit too far and started to believe that sleep didn't really matter when I could be productive on a project instead. I was also in my early twenties and felt pretty much invincible. As I've progressed in my career I've realized that the work I can accomplish at 3:00am does not stand up to work I can get done after a full night's sleep. I don't think that staying up all night working on school assignments was the wrong way to do things since we also worked all day long, but now that I have a stable job and much looser time constraints on both career and personal projects I think it's definitely important to get as much sleep as is needed.</p><h3 id=\"network-as-much-as-possible\">Network as much as possible</h3><p></p><h3 id=\"start-now-there-s-never-a-good-time\">Start now, there's never a good time</h3><p></p><h3 id=\"leave-your-comfort-zone\">Leave your comfort zone</h3><p></p><h3 id=\"as-our-circle-of-knowledge-increases-in-size-the-circumference-of-darkness-expands-even-quicker-albert-einstein\">\"As our circle of knowledge increases in size, the circumference of darkness expands even quicker.\" - <strong>Albert Einstein</strong></h3><p>This is a famous quote from Albert Einstein literally talking about how the universe expands faster than we can observe it. I, and many people, like to look at it metaphorically in how an individual or all of humanity's knowledge increases we also learn that there is so much more out there to learn about.</p><p>As a university student who was constantly learning new methods and technology I made this realization for myself. During one of our long nights at the school I said to my friends \"The more you know, they more you realize you don't know.\" It wasn't until recently that I found out my realization was just a less eloquent version of a quote by one of the most famous scientists in history.</p><h3 id=\"learn-to-decipher-the-good-advice-from-the-bad\">Learn to decipher the good advice from the bad</h3><p></p><h3 id=\"dollar-stack-proportionality\">Dollar / Stack Proportionality</h3><p>This is the concept that using \"enterprise\" technology stacks will earn you a higher salary than \"startup\" stacks. I'm not really sure how true this is anymore.</p><p>My first career job out of university was for a medium size enterprise writing C# and Visual Basic with MSSQL databases. In school I had learned a wide variety of technologies including programming languages such as C#, Java, PHP, C, C++, JavaScript, and Python. I discovered near the end of my schooling that I really liked Node and Python in combination with Docker. Since my job was in the much more \"enterprise\" technologies I was missing out on learning the skills I was actually interested in. I mentioned this to a colleague and he responded saying that the best way to earn a high salary in computing is to work with enterprise technologies. It made sense since at the time C# was a proprietary language from Microsoft where you had to pay for expensive Visual Studio licenses but it came with support. Only larger companies could afford these technologies but they choose to use them since the idea of a technology with a support is required in order for the bureaucracy to feel comfortable with the risk level.</p><p>Today I know more people working for smaller companies with \"start-upy\" technologies like Node and Go earning exceptional salaries than I do people working for larger companies using Java and Scala. I think the adoption of cloud computing, Kubernetes, and functions-as-a-service has enabled companies to break away from the \"Java ecosystem\" or Microsoft ecosystem in favor of \"best tool for the job\" that can be hosted anywhere they want for very cheap. Support is now offered from AWS, Azure, or GCP and the open source community provides enough support for the languages that are all open source now.</p><h3 id=\"don-t-focus-on-using-the-same-technology-for-everything-instead-use-the-right-tool-for-the-job\">Don't focus on using the same technology for everything, instead use the right tool for the job</h3><h3 id=\"mushroom-management\">Mushroom Management</h3><p></p><h3 id=\"the-washington-listen\">The Washington Listen</h3><blockquote>To some listening is a period of silence where someone else talks before you say what you were planning to say all along. We see these exchanges in nearly every \"debate\" on television. It's the candidate sitting on the stool waiting for the light to go on then standing up and saying their prearranged talking points while someone else says their prearranged talking points back at them. It's just words reaching ears but not getting into a conscious brain. That's the \"Washington Listen\".<br>   - A Higher Loyalty, James Comey, 2018</blockquote><p>James Comey talks about his experience with political types during his time Washington DC observing that a majority of them are terrible listeners. I've experienced this several times with various friends and coworkers but I'd not put a name to it until I read A Higher Loyalty. In order to have a productive discussion with ones team one must be willing to listen and take into consideration the opinions and desires of one's teammates.</p>",
    "created_at": "2020-08-09T18:22:43.000Z",
    "updated_at": "2020-08-09T21:58:48.000Z",
    "published_at": "2020-08-09T21:58:48.000Z",
    "preview": "Quotes and other things"
  }
]
